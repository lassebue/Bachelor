\thispagestyle{fancy}
\chapter{Feature extraction og model træning}
\label{chp:matlabChapter}
I dette projekt anvendes matlab til at løse en række essentielle opgave, der omtales i machine learning sektionen \ref{sec:machineLearning}. I det følgende kapitel, vil disse opgaver blive beskrevet nærmere. \\
Det er valgt at anvende MATLAB til at løse disse opgave, da det er et kendt værktøj med et bredt spektre af veldokumenterede funktionaliteter indenfor databehandling\citep{matlabFeatures} og træning af machine learning modeller\citep{matlabML}. Disse er netop problematikkerne, der i dette projekt er fokus på. 

\section{Dataimport}
Data er en vigtig del af machine learning, da det er herfra genkendelige features kan udtrækkes og anvendes til at træne de modeller, hvis formål er at genkende generel data fra forskellige kilder. I dette projekt anvendes EMG data indsamlet vha. den udviklede Data Collection Application beskrevet i kapitel \ref{chp:dataingsamlingChapter}, hvor den nødvendige data til træning gemmes i .csv-filer. I denne sektion vil det blive beskrevet, hvordan den opsamlede data fra den udviklede Data Collection Application, importeres fra .csv-filer og klargøres til feature extraction.
\\\\
Før den indsamlede data er klar til den nødvendig databehandling, skal den gennem en række trin for at omstruktureres, således at feature extraction kan ske på mindre subset af dataet.\todola{måske skulle de overordnede trin også skrives: Skaf træningssæt, træn model} Efter import af filerne, omstrukturering og feature extraction, er træningssættet klar. \todola{klar til at blive anvendt i MATLAB's Classification Learner/ kan træningssættet anvendes til modeltræning} 
\\ Omstruktureringen består af følgende trin:
\begin{description}
	\item[Første trin:] Den indsamlede data skal importeres og konverteres fra .csv-formatet til arrays.\\\\
		Data fra hver kolonne i .csv-filerne overføres til et array til senere behandling
	\\\\
	For hver vindue af datasamples, skal udvalgte værdier fra .csv-filerne gemmes. Der er her tale om \textit{pose}, \textit{orientering} og \textit{testPerson}. Disse værdier skal kopieres, således at hver værdi optræder for hver vindue med samples.

  \item[Andet trin:] Arrays med EMG data opdeles i vinduer. 
  \\\\
  Efter dataet fra EMG sensorerne er gemt, opdeles de i såkaldte vinduer som er intervaller af data samples med en fast størrelse. Det er disse vinduer, der laves feature extraction over.
  \\\\
  Mangler et antal sample, således at et vindue ikke får den rette størrelse fjernes det fra de øvrige vinduer. 
    \item[Tredje trin:] Øvrige udvalgte værdier tilføres fra .csv-filen til samplevinduerne, hvor de dubleres, således at hver samplevindue har egne tilhørende værdier.
  \\\\
  For hver vindue af datasamples skal de udvalgte værdier dubleres, således at hver værdi optræder for hver vindue. Der er her tale om \textit{pose}, \textit{orientation} og \textit{testPerson}.
  
  \item[Fjerde trin:] \textit{pose}-værdierne konverteres til MATLAB typer \textit{categorical}
  \\\\
  Efter \textit{pose}-værdierne er dubleret til hver vindue konverteres de til \textit{categorical}s, hvilket er typen MATLAB anvender til \textit{response}. Dette er essentielt, da poses netop er det der ønskes, at de modeller er i stand til at genkende. Som tidligere nævnt dækker navnet \textit{pose} i .csv-filerne over pose ID\todokr{Det skal nævnes tidligere!}, der konverteres derfor fra \textit{integer}-værdier til \textit{categorical}-typen. \todola{skal typer måske skrive med itatic}
\end{description}
Det er de fire trin, der udføres på alle importerede .csv-filer. Filerne behandles gennem funktionen \textit{importFileFuncOri},\todola{Navnet på funktionen skal måske ændres} der tager arrays med hver af de udvalgte værdier som inputs. Disse værdier er vinduer fra hver af de 8 EMG sensorer og derudover \textit{pose}-, \textit{orientation}- og \textit{testPerson}-værdier til hvert vindue. Videre tager funktionen stien og navnet til en enkelt .csv-filer som input, hvilket er den specifikke fil, der behandles. Ved kald af funktionen kan array-parametrene være med data eller uden, funktionaliteten er den samme. Funktionen tilføjer værdierne for hvert af de nye vinduer til array-parametrene, og returnerer de resulterende arrays. 

Den anvendte funktion \textit{importFileFuncOri} er genereret vha. MATLAB's \textit{uiimport}-funktion\citep{matlabUiimport}, hvor en import GUI, som kan ses på figur \ref{fig:dataImport}, præsenterer en række data import funktioner. En af disse genererer ud fra de foretagede valg i dialogboksen, en MATLAB-funktion, der importerer den valgte filtype. Når MATLAB-funktionen er gemt, modificeres dens script til at udføre de beskrevne trin, der skal udføres før feature extraction kan finde sted.

\myFigure{uiimport}
{
	Her ses MATLAB's import dialogboks med data indsamlet fra Data Collection Application. Videre ses en dropdown menu øverst til højre under \textit{Import Selection}-knappen, hvor tre mulighed for valg af import kan findes. Her er mulighederne: \textit{Import Data}, \textit{Generate Script} og \textit{Generate Function}. \textit{Generate Function}-funktionen anvendes i dette projekt til at generere en MATLAB-funktion til dataimport.
 }{fig:dataImport}{1}

Vha. denne funktion kan de enkelte .csv-filer importeres til MATLAB, hvorefter EMG-signalerne kan analyseres og efterfølgende feature extraction kan foretages.

\section{Feature extraction}

For at være i stand til at træne machine learning modeller, skal der fra den datakilde der behandles, være generelle kendetegn, som altid vil kunne identificeres uanset, hvilket datasæt der undersøges. Disse features skal dog identificeres og udtrækkes før træningen af modellerne kan påbegyndes. I det følgende vil det blive beskrevet, hvorledes analyse og feature extraction af EMG-signalerne er foretaget gennem projektet.
\\\\
Der har fra projektgruppens side været en hypotese om, at niveauet af aktivitet på Myo'ens individuelle sensorer, vil kunne anvendes som features, da forskellige muskler er aktive ved forskellige håndbevægelser. Lukkes hånden f.eks. er det især muskel grupper på indersiden af armen, der aktiveres. Omvendt forholder det sig, hvis håndens fingre strækkes, hvorved muskel grupper på ydersiden af armen aktiveres. \mySubFigure{diagnosticOpenHand}{diagnosticClosedHand}{
I hver figure, \ref{open} og \ref{closed}, ses 8 EMG-grafer for hver sensor, her med titlerne \textit{pod0}, \textit{pod1} osv. Tiden ses på den horisontal akse og amplituden på den vertikale akse. Det ses på figur \ref{open} for pose med udstrakte fingre, at amplituden ved \textit{pod3}er større end \textit{pod3} på figure \ref{closed}. Videre ser \textit{pod0} og \textit{pod1} på figur \ref{closed} ud til at være større end de tilsvarende pods på figur \ref{open}.
}{Udstrakte fingre}{Lukkes hånd}{fig:diagnostic}{open}{closed}
Videre er teorien blevet underbygget ved test af Myo'en på Thalmic Labs' diagnostics-hjemmeside\citep{myoDiagnostik}, hvor en real time graf over måleringer fra Myo'ens sensorer giver indtryk af at hypotesen kan være sand. Denne hjemmeside er blevet anvendt til at studere sensorernes overordede output ved forskellige poses. Screen shots af real time grafen fra diagnostics-hjemmesiden kan ses med to poses på figur \ref{fig:diagnostic}.\\\\
Andre mulige features der er blevet overvejet er: varians, principal components og specifikke frekvenser. Her er frekvens analyse blevet fravalg, da Myo'en kun er i stand til at sample med en frekvens på 200 Hz og EMG-frekvens spektret ligger mellem 25 Hz og adskillige kilohertz\citep{websterEMG}, hvorved samlefrekvensen er for lav i forhold til EMG-signalers Nyquist Rate. Videre er størrelsen på samlingsvinduerne interessante i denne overvejelse, da intentionen er at anvende de trænede modeller til styring af CrustCrawleren. I denne sammenhæng er det vigtigt at tage højde for systemet responsiveness, hvor størrelse på vinduerne er afgørende for hvor lang tid, der går fra samplet data modtages, til modellen har klassificeret dataet fra vinduet, da vinduet "fyldes" før feature extraction.\todoall{Det skal lige tjekkes om det er rigtigt} Jo mindre vinduerne er, jo hurtigere respons vil systemet kunne få. Dog vil små vinduer resultere i at mindre brugbar frekvensinformation vil kunne udtrække, hvorved frekvenser ikke vil være en kilde til features uden det påvirker reaktionshastighed. Derfor er det blevet vurderet, at der kan ses bort fra frekvenser som features til modeltræningen.\\\\
Dog blev det vurderet, at de øvrige tre features vil kunne anvendes som features. Derfor er der i MATLAB blevet udviklet funktioner til at udregne EMG-signalernes gennemsnit, varians og First Principal Component for at kunne undersøge, hvorvidt disse vil kunne anvendes til modeltræning.  \todoall{Skal måske referere til bilag med MATLAB-funktionerne}
For at test de udvalgte værdier som features, der er blevet udviklet et script, som udfører følgende funktionaliteter:
\begin{myItemize}
\item Importerer udvalgte .csv-filer og gemmer alle vinduernes værdier i arrays
\item Ensretter alle EMG-samples ved kvadrering 
\item Gemmer vinduernes EMG-samples i en MATLAB-table
\item Beregner for hver sensor middelværdierne for hvert vindues kvadreret EMG-signal
\item Beregner  for hver sensor variansen for hvert vindues kvadreret EMG-signal
\item Beregner  for hver sensor First principal component for hvert vindues kvadreret EMG-signal
\item Opretter ny MATLAB-table, hvor de beregnede features gemmes
\item Tilføjer den optaget pose for hvert vindue til den MATLAB-table, som indholder de beregnede features
\item Åbner MATLAB Classification Learner\citep{matlabClassificationLearner}
\end{myItemize}
Efter import af .csv-filerne kan et bedre indtryk dannes ved at studere de forskellige sensor outputs. På figur \ref{fig:rawEmgData} er rå sensordata plottet for hver sensor ved forskellige poses. Her ses igen en tendens, hvor de forskellige sensorers position, giver anledning til variation i amplituden mellem de tre poses. Igen synes den omtalte hypotese at blive underbygget, denne gang af den opsamlede data fra Myo'en.
\myFigure{RawEmgMedXlabel}
{
	Her ses et eksempel på rå EMG-signaler fra de 8 EMG-sensorer efter import. På x-aksen er tiden for målingerne, hvor der er 5 ms mellem hver sample. På y-aksen er amplituden, denne er uden enhed. Her er signalerne fra hver pose repræsenteret med forskellige farver. EMG-signalerne markeret med rødt er lavet med en lukket hånd, de blå er lavet med en åben hånd og de gule er lavet med en hånd i hvile. Særligt ved sensor 6 og 7 ses forskelle i amplituden mellem poses med åben og lukket hånd. 
 }{fig:rawEmgData}{1}
Ved at køre det udviklede script og derefter vælge hvilke .csv-filer skal med i træningssættet, bliver vinduerne konstrueret og deres features udtrukket. Herved vil modeller efterfølgende kunne trænes. På figur \ref{fig:meanEmgData} ses middelværdier for vinduer optaget ved de forskellige poses. Graferne giver et godt overblik over, hvordan middelværdierne varierer mellem de forskellige poses for hver sensor. Tilsvarende grafer for de øvrige features kan ses i bilag \ref{fig:pcaEmgData} og \ref{fig:stdEmgData}. Det er variationer som disse, der ved modeltræning anvendes til at opbygge de classifiers, som kan genkendes poses ud fra EMG-vinduer. Hvordan træningen disse classifiers er blevet udført i dette projekt, vil blive beskrevet i den følgende sektion.

\myFigure{EmgMeanPlot}
{
	På graferne ses 400 vinduer med deres tilhørende middelværdier. På x-aksen er vinduerne, og opad y-aksen er middelværdierne, som er enhedsløse. Vinduernes middelværdier markeret med rødt er optaget fra en lukket hånd, de blå er optaget fra en åben hånd og de gule er optaget fra en hånd i hvile. Det ses tydeligt på middelværdierne fra hånden i hvilke, at der ingen aktivitet er, på nær enkelte vinduer. Både for vinduer optaget ved åben og lukket hånden ses aktivitet, dog er der ved sensor 7 for den lukkede hånd ingen aktivitet. Ligeledes forholder det sig ved sensor 6 for vinduer optaget med åben hånd.
 }{fig:meanEmgData}{1}

\section{Modeltræning}
Når import og feature extraction er udført, er den næste del træningen af en machine learningmodellerne. Udførelsen af dette vil i denne sektion være beskrevet.

\myWrapFigure{matlabModeller}{De forskellige machine learning modeller man kan træne ud fra sit data. Der bliver valgt Bagged Trees da den giver en præcise model. Denne model er beskrevet nærmere i sektion \ref{sec:baggedTrees} }{fig:matlabModeller}{0.4}{r}

For at finde ud af om det er muligt at genkende poses med Myo'en og machine larning, er der først trænet modeller , hvor dataet er opsamlet fra Myo'en hvor den sidder på én måde. Det blev bekræftet at det var muligt at genkende poses vha. machine learning på EMG-signaler fra Myo'en. Efterfølgende er nye data indsamlet hvor der mellem hver indsamling er lavet en lille rotation af Myo'en på armen, og der opsamles dermed data i positioner hele vejen rundt på underarmen.

Træningen af machine learning modellerne foregår i Matlabs Classification Learner\citep{matlabClassificationLearner}. Classification Learner er et værktøj der giver mulighed for træning af mange forskellige slags machine learning modeller. Under træningen er flere forskellige afprøvet for at se deres nøjagtighed. Et par af disse er gennemgået i kapitel \ref{chp:mlm}.

Classification Learneren åbnes og der startes en ny session. Her skal valideringsmetoden vælges. Holdout-validation vælges da det er en stor mængde data der skal trænes på. Med Holdout-validering vælges en procentdel af dataet der holdes ude af træningen. Den del der holdes ude bruges til test for at se hvor god modellen er\citep{matlabValidation}.

\myWrapFigure{CLHistory}{Historie over de trænede modeller. Bagged Tree øverst, markeret med størst præcision på 99,1\%. Hvorimod Simple Tree f.eks. kun har en præcision på 71,2\%}{fig:CLHistory}{0.35}{l}

Træningen er modellerne er nu klar til at blive gennemført og der skal vælges hvilken machine learning model der skal bruges. På figur \ref{fig:matlabModeller} ses valgmulighederne.
Bagged Trees vælges, og modellen trænes.
Der kan trænes flere modeller i én session, det bliver derfor nemt at sammenligne dem, for at se hvilke der er bedst. Som figur \ref{fig:CLHistory} viser, vil de trænede modeller vises i historikken i Classification Learneren, hvor præcisionen er vist.

Når en model er blevet trænet er det muligt at se, hvornår den har risiko for at lave hvilke fejl. Værktøjet Confusion Matrix, er en nem og overskuelig måde at se modellens fejl på. På en Confusion Matrix er de testede input op ad y-aksen og modellens output, altså posegenkendelsen, ud af x-aksen. De tre poses der arbejdes med har et nr. fra 0 til 2. Det kan nu ses at hvis inputtet er 1, er der et x antal procent chance for at ouputtet også er 1. Omvendt viser den også hvad chance er for at outputtet bliver 2, selvom inputtet er 1.

\myFigure{CLConfusionMatrix}{På y-aksen ses input 0, 1 og 2. Giver der et pose input 0, vil der være 97,5\% chance for at outputtet og dermed modellen genkendelse er 0. Det ses også at der er 0,7\% risiko for at ouputtet bliver 1, og 1,9\% risiko for output 2. Der er testet med 914 0 inputs, hvoraf 891 giver det sande output 0. 6 giver output 1 og 17 giver output 2.}{fig:clcm}{0.7}

\section{Resultater}