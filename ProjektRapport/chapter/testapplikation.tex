\thispagestyle{fancy}
\chapter{Testapplikation}
\label{chp:testapp}
I dette kapitel vil testapplikationen til anvendelsen af systemet være beskrevet. Denne er udviklet ud fra kravspecifikationen, \citep{RefWorks:8}, der har dannet grundlag for applikationens funktionalitet. \\
Det er fra starten af projektet besluttet, at applikationen til systemet udvikles i Windows Presentation Foundation (WPF) i Microsoft Visual Studio, da dette er et allerede kendt framework, og det er derfor hurtigt at starte udviklingen. WPF er desuden valgt til udviklingen, da det indeholder gode værktøjer til arbejde med GUI, hvilket gør, at brugeren af applikationen nemt kan avende systemets funktioner.

Denne applikation stiller krav til anvendelsen af den opsamlede data og den model træning, der er udviklet. Applikationen skal være i stand til at åbne og lukke CrustCrawler-kloen ved hjælp af genkendelse af poses med Myo'en.

\section{Software arkitektur}
Det er valgt til CrustCrawler Applikationen, som testapplikationen hedder, at den skal udvikles i en MVVM\footnote{Model-View-ViewModel} arkitektur\citep{RefWorks:14}. MVVM er et WPF design pattern, der er brugt i en vid udstrækning af applikationer med grafisk brugergrænseflade. Dette er et naturligt valg, da der udvikles på en XAML platform. .xaml-filen er view'et i MVVM. Denne bliver separeret fra model-laget med en ViewModel. MVVM er et design pattern, der blev udviklet hos Microsoft ud fra Model-View-Presenter arkitekturen\citep{mvp}. Det er i modellen, at applikationens funktionalitet ligger. De er begge koblet sammen af en ViewModel. Dette gør udviklingen af applikationen mere overskuelig og nem at gå til.

\myFigure{MVVM}{Den implementerede arkitektur i applikationen. View'et er adskilt fra modellen med en ViewModel. Modellen er delt op i flere klasser, for at opfylde SOLID-pricipperne\citep{RefWorks:10}, hvor det giver mening i applikationen.}{fig:mvvm}{0.6}

På figur \ref{fig:mvvm} ses den overordnede struktur i, hvordan klasserne er placeret. Formålet med denne figur er at give et overblik, derfor er alle klasser ikke med. Modellen, som består af flere forskellige klasser, er vha. MVVM separeret fra viewet, hvis design findes i .xaml-filen, MainWindow.xaml.

\myFigure{CCAClassDiagram}{Klasse diagram over CrustCrawler applikationen. Klasserne af lavet ud fra SOLID-principperne, og anvender interfaces til undgå høj kobling. Hver klasse har kun ét ansvar de skal sørge for. Applikationen er også åben for udvidelser. Der kan f.eks. tilføjes nye poses, uden der skal ændres i allerede eksisterende klasser. Der skal blot tilføjes et interface der nedarver fra IPoseHandlerMkI, hvor der kan tilføjes nye funktionaliteter, som kan udføres ved genkendelse af de nye poses.}{fig:cd}{1}

Under udviklingen er der taget højde for SOLID-principperne\citep{RefWorks:10}, derfor udformer applikationen klassediagram som det ses på figur \ref{fig:cd}. Single responsibility\citep{RefWorks:9} er overholdt, og dermed er klasser opdelt i projektet, sådan at de har hvert deres ansvar. Matlab sørger for al kommunikation med MATLAB. I denne klasse initialiseres og startes MATLAB serveren, desuden sendes kommandoer MATLAB herfra. I CCManagement, er metoderne de forskellige kommandoer, der kan kaldes for at styre CrustCrawleren. Der kaldes f.eks. metoden OpenClaw(), når CrustCrawler-kloen skal åbnes. CCManagement kalder Matlab som sender kommandoen til MATLAB serveren. I klassen Recognition startes genkendelsesmetoderne, der gennem Matlab-klassen, og dermed MATLAB serveren, sendes vinduer med datasamples og Myo'ens orientering til at blive genkendt af machine learning modellen.



\section{Brugergrænseflade}

\myWrapFigure{CCA}{CrustCrawler Applikationens GUI}{fig:cca}{0.4}{r}
GUI'en i applikationen er lavet meget simpel. Den bærer præg af at være beregnet til at teste systemet. Figur \ref{fig:cca} viser applikationens GUI. Den giver adgang til nogle forskellige funktionaliteter, bl.a. startes der med at tjekke orientering, på armbåndet. Dette giver mulighed for at bære Myo'en med en hvilken som helst orinetering, bare den er blevet checket når Myo'en er påført. For at kunne teste forbindelsen til CrustCrawleren, er der blevet lavet Open Claw og Close Claw knapper, så det hurtig og nemt er muligt at se, om der er forbindelse til CrustCrawleren. Det er i sektion \ref{sec:ktc} forklaret hvordan der kommunikeres ud til CrustCrawleren.

Knapperne \textit{Start Recognition} og \textit{Stop Recognition} er, hvor anvendelsen af den opsamlede data og de udviklede modeller sættes i gang. Ved tryk på \textit{Start Recognition} vil \textit{Window Count} og \textit{Current Window} begynde at tælle op. \textit{Current Window} er det vindue af datasamples, der er ved at blive klassificeret af modellen. \textit{Window Count} er alle de vinduer, der er samlet med datasamples.

\section{Genkendelse}
\todokr{Forslag til ændring:
Når et vinduet med datasamples fra et EMG-signal er blevet optaget, skal der udføres feature extraction, hvorefter de resulterende features kan genkendelse af machine learningen modellen. 
Her skal også være noget, om hvad der skar i MATLAB i dette afsnit!}

For der kan genkendes håndtryk skal der være noget at stille de data op i mod, som kommer fra Myo'en. Det er her alt den opsamlede data der er trænet en model på bruges. Dataen der kommer direkte fra myoen, bliver sendt fra applikationen sat op imod den trænede model der er blevet gennemgået i kapitel \ref{chp:matlabChapter}, og der bliver set på hvilken den mest ligner. 

\myFigure{SekvensDiagramRecognition}{Flow der gennemgåes ved start af genkendelse. Ved tryk på Start Recognition, sendes et command til ViewModel, der starter recognition i Recognition-klassen, som laver administrer genkendelsen signalerne fra Myo'en. Alt efter hvilken pose der genkendes, vil CCManagement lytte efter events sendt af Recognition-klassen og kalde funktionen, der matcher den genkendte pose.}{fig:sdr}{1}
\todokr{Der skal noget om genkendelsen med i MATLAB her}
\section{Kommunikation med CrustCrawler}
\label{sec:ktc}
Som nævnt tidligere foregår al kommunikation med CrustCrawleren igennem Matlab-klassen. Her sørges der for at kalde funktioner i en MATLAB Automation\todokr{Det er ikke første gang den bliver nævnt} server\footnote{Fremover nævnt som MATLAB server} der bliver åbnet under initieringen af Matlab-klassen. Kald der bliver lavet i MATLAB serveren er både, når der skal sende vinduer til genkendelse, men også når der kaldes funktioner til at styrere CrustCrawleren. På sekvensdiagrammet på figur \ref{fig:sd} ses de kald, der bliver foretaget, når kloen på CrustCrawleren skal åbnes.

\myFigure{Sekvensdiagram}{OpenClaw() i CCManagement klassen kaldes, som kontakter Matlab.cs da der skal kontakt til MATLAB serveren. MATLAB serveren bliver kaldt og i MATLAB er der udviklet funktioner til at manøvrere CrustCrawleren rundt og styre kloen. Funktionen OpenClaw() i MATLAB serveren kalder funktionen MoveServo(), denne skriver ud til CrustCrawleren at servo nummer 7 skal køre til en bestemt anvist position.}{fig:sd}{1}

Processen for at kalde funktioner i MATLAB fra WPF-applikationen foregår som følger \citep{RefWorks:15}:
\begin{enumerate}
%	\itemsep -0.9em 
	\item Start MATLAB Automation Server og lav en instans heraf
	\item Sæt sti til mappe, hvor MATLAB funktioner ligger
	\item MATLAB-funktioner kan efterfølgende kaldes fra WPF-applikationen.
\end{enumerate}

\myFigure{USB2Dynamixel}{USB2Dynamixel enhed der bruges for at lave en seriel port fra en af computerens USB porte. Igennem USB2Dynamixel kan CrustCrawleren tilkobles computeren.}{fig:usb2d}{0.4}

CrustCrawleren tilkobles computeren gennem en USB2Dynamixel, se figur \ref{fig:usb2d}. USB2Dynamixel er brugt for at lave en seriel port igennem computerens USB port. Til denne er en driver og et .dll bibliotek med en tilhørende headerfil. Dynamixel.dll og dynamixel.h. Disse filer loades begge i MATLAB-koden, hvor biblioteket giver mulighed for at kalde nogle forskellige funktioner, som CrustCrawleren kan reagere på. Driveren er USB2Dynamixel \citep{agaverobot} \todokr{lav reference til manual hvis denne laves} og er frit tilgængelig for alle. Denne kan dog kun bruges med en USB2Dynamixel enhed og Dynamixel servoer.

\section{Delkonklusion}
Det er nu muligt som bruger med denne applikation og en Myo at genkende håndtrykkene åben hånd og lukket hånd vha. en trænet machine learning model. Applikationen står for at få data fra Myo'en og sende det til en MATLAB server, hvor der beregnes, og sammenlignes med den trænede model og der sendes resultat tilbage til applikationen. Genkendelsen anvendes på en CrustCrawler robot arm, der åbnet og lukkes alt efter genkendelsen.